{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlinaZemlyakova/CompLing-2021-2022/blob/main/hw11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 11. Машинный перевод"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yj7aripVIsbG",
      "metadata": {
        "id": "Yj7aripVIsbG"
      },
      "source": [
        "## Задание 1 (6 баллов + 2 доп балла).\n",
        "Нужно обучить трансформер на этом же или на другом корпусе (можно взять другую языковую пару с того же сайте) и оценивать его на всей тестовой выборке (а не на 10 примерах как сделал я). \n",
        "\n",
        "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Подсказка: модель может предсказывать батчами.\n",
        "\n",
        "Записи занятий: https://colab.research.google.com/drive/13FfVwDYr88VX_qmPcMme5RW7eMwe5FH8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "947b3313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0616e4-0cfd-462f-b0b5-db0abf9b509e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Installing collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers matplotlib sklearn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import Lowercase\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "947b3313"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d202c4",
      "metadata": {
        "id": "05d202c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b1242f-3861-4427-b1a7-033efa581414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-24 10:11:25--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  31.9MB/s    in 4.2s    \n",
            "\n",
            "2022-05-24 10:11:30 (27.4 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n",
            "\n",
            "--2022-05-24 10:11:30--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  24.9MB/s    in 2.6s    \n",
            "\n",
            "2022-05-24 10:11:33 (24.9 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n",
            "\n",
            "--2022-05-24 10:11:33--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru’\n",
            "\n",
            "opus.en-ru-test.ru  100%[===================>] 298.50K   832KB/s    in 0.4s    \n",
            "\n",
            "2022-05-24 10:11:34 (832 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n",
            "\n",
            "--2022-05-24 10:11:34--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en’\n",
            "\n",
            "opus.en-ru-test.en  100%[===================>] 169.25K   624KB/s    in 0.3s    \n",
            "\n",
            "2022-05-24 10:11:34 (624 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"
      ],
      "metadata": {
        "id": "k7S2ZsHfin8O"
      },
      "id": "k7S2ZsHfin8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(WordPiece(), )\n",
        "tokenizer_en.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_en = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en )\n",
        "\n",
        "tokenizer_ru = Tokenizer(WordPiece(), )\n",
        "tokenizer_ru.normalizer = normalizers.Sequence([Lowercase()])\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_ru = WordPieceTrainer(\n",
        "          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru )"
      ],
      "metadata": {
        "id": "-0IM5VE4jD8S"
      },
      "id": "-0IM5VE4jD8S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.decoder = decoders.WordPiece()\n",
        "tokenizer_ru.decoder = decoders.WordPiece()"
      ],
      "metadata": {
        "id": "DzsttjsxjJPl"
      },
      "id": "DzsttjsxjJPl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, tokenizer, target=False):\n",
        "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[SEP]')]"
      ],
      "metadata": {
        "id": "gc289yWJHHkE"
      },
      "id": "gc289yWJHHkE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_en = [encode(t, tokenizer_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, target=True) for t in ru_sents]"
      ],
      "metadata": {
        "id": "KoHA-HpeHNiB"
      },
      "id": "KoHA-HpeHNiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_en, max_len_ru = 20, 22"
      ],
      "metadata": {
        "id": "sWYnosIbHQq5"
      },
      "id": "sWYnosIbHQq5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')"
      ],
      "metadata": {
        "id": "qGM4eAmHHTBr"
      },
      "id": "qGM4eAmHHTBr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_en = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              X_en, maxlen=max_len_en, padding='post', value=tokenizer_en.token_to_id('[PAD]'))\n",
        "\n",
        "X_ru_out = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[1:] for x in X_ru], maxlen=max_len_ru-1, padding='post', \n",
        "              value=tokenizer_en.token_to_id('[PAD]'))\n",
        "\n",
        "X_ru_dec = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "              [x[:-1] for x in X_ru], maxlen=max_len_ru-1, \n",
        "              padding='post', value=tokenizer_ru.token_to_id('[PAD]'))\n",
        "\n",
        "X_en_train, X_en_valid, X_ru_dec_train, X_ru_dec_valid, X_ru_out_train, X_ru_out_valid = train_test_split(X_en, \n",
        "                                                                                                      X_ru_dec, \n",
        "                                                                                                      X_ru_out, \n",
        "                                                                                                      test_size=0.05)"
      ],
      "metadata": {
        "id": "NdogGJFGHLWi"
      },
      "id": "NdogGJFGHLWi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    \"\"\"Calculate the attention weights. \"\"\"\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # add the mask to zero out padding tokens\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "vmnWkDAOHdVj"
      },
      "id": "vmnWkDAOHdVj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4b51870"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # linear layers\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # split heads\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # scaled dot-product attention\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # concatenation of heads\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # final linear layer\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "id": "f4b51870"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c48cea2"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, PAD_IDX), tf.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "id": "5c48cea2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21c0c899"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "id": "21c0c899"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e120bbe5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "id": "e120bbe5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68472627"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "id": "68472627"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89dcc42e"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "id": "89dcc42e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2f90e7c"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "id": "a2f90e7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e9f89b8"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            max_len,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "id": "8e9f89b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e356741b"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                max_len,\n",
        "                name=\"transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "    # mask the future tokens for decoder inputs at the 1st attention block\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "    # mask the encoder outputs for the 2nd attention block\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "    enc_outputs = encoder(\n",
        "      vocab_size=vocab_size[0],\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      max_len=max_len[0],\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    dec_outputs = decoder(\n",
        "      vocab_size=vocab_size[1],\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      max_len=max_len[1],\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "id": "e356741b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c35ce0f"
      },
      "outputs": [],
      "source": [
        "L  = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none',)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    loss = L(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, PAD_IDX), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "id": "6c35ce0f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "747835a8"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "id": "747835a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "542fcc43",
        "outputId": "1f33bc30-975a-4f37-e122-db4019a880f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# small model\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "\n",
        "# average model\n",
        "# NUM_LAYERS = 6\n",
        "# D_MODEL = 512\n",
        "# NUM_HEADS = 8\n",
        "# UNITS = 2048\n",
        "# DROPOUT = 0.1\n",
        "\n",
        "\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "with mirrored_strategy.scope():\n",
        "    model = transformer(\n",
        "        vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n",
        "        num_layers=NUM_LAYERS,\n",
        "        units=UNITS,\n",
        "        d_model=D_MODEL,\n",
        "        num_heads=NUM_HEADS,\n",
        "        dropout=DROPOUT,\n",
        "        max_len=[max_len_en, max_len_ru])\n",
        "\n",
        "#     learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "    def accuracy(y_true, y_pred):\n",
        "#         y_true = tf.reshape(y_true, shape=(-1, max_len_ru - 1))\n",
        "        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model_ruen',\n",
        "                                                monitor='val_loss',\n",
        "                                                verbose=1,\n",
        "                                            save_weights_only=True,\n",
        "                                            save_best_only=True,\n",
        "                                            mode='min',\n",
        "                                            save_freq='epoch')"
      ],
      "id": "542fcc43"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((X_en_train, X_ru_dec_train), X_ru_out_train, \n",
        "             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n",
        "             batch_size=150,\n",
        "             epochs=15,\n",
        "             callbacks=[checkpoint]\n",
        "             )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a0ff28-5e22-4cd9-f995-af199b9b498b",
        "id": "CQ3jGIPB_p_y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 2.3627 - accuracy: 0.2137\n",
            "Epoch 1: val_loss improved from inf to 1.87555, saving model to model_ruen\n",
            "6334/6334 [==============================] - 925s 144ms/step - loss: 2.3627 - accuracy: 0.2137 - val_loss: 1.8756 - val_accuracy: 0.2594\n",
            "Epoch 2/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.8285 - accuracy: 0.2626\n",
            "Epoch 2: val_loss improved from 1.87555 to 1.72557, saving model to model_ruen\n",
            "6334/6334 [==============================] - 916s 145ms/step - loss: 1.8285 - accuracy: 0.2626 - val_loss: 1.7256 - val_accuracy: 0.2760\n",
            "Epoch 3/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.7153 - accuracy: 0.2746\n",
            "Epoch 3: val_loss improved from 1.72557 to 1.66585, saving model to model_ruen\n",
            "6334/6334 [==============================] - 916s 145ms/step - loss: 1.7153 - accuracy: 0.2746 - val_loss: 1.6659 - val_accuracy: 0.2831\n",
            "Epoch 4/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.6589 - accuracy: 0.2808\n",
            "Epoch 4: val_loss improved from 1.66585 to 1.63402, saving model to model_ruen\n",
            "6334/6334 [==============================] - 915s 144ms/step - loss: 1.6589 - accuracy: 0.2808 - val_loss: 1.6340 - val_accuracy: 0.2871\n",
            "Epoch 5/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.6237 - accuracy: 0.2848\n",
            "Epoch 5: val_loss improved from 1.63402 to 1.61278, saving model to model_ruen\n",
            "6334/6334 [==============================] - 916s 145ms/step - loss: 1.6237 - accuracy: 0.2848 - val_loss: 1.6128 - val_accuracy: 0.2895\n",
            "Epoch 6/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5989 - accuracy: 0.2877\n",
            "Epoch 6: val_loss improved from 1.61278 to 1.59712, saving model to model_ruen\n",
            "6334/6334 [==============================] - 920s 145ms/step - loss: 1.5989 - accuracy: 0.2877 - val_loss: 1.5971 - val_accuracy: 0.2922\n",
            "Epoch 7/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5799 - accuracy: 0.2900\n",
            "Epoch 7: val_loss improved from 1.59712 to 1.58606, saving model to model_ruen\n",
            "6334/6334 [==============================] - 924s 146ms/step - loss: 1.5799 - accuracy: 0.2900 - val_loss: 1.5861 - val_accuracy: 0.2932\n",
            "Epoch 8/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5626 - accuracy: 0.2918\n",
            "Epoch 8: val_loss improved from 1.58606 to 1.57947, saving model to model_ruen\n",
            "6334/6334 [==============================] - 925s 146ms/step - loss: 1.5626 - accuracy: 0.2918 - val_loss: 1.5795 - val_accuracy: 0.2943\n",
            "Epoch 9/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5481 - accuracy: 0.2935\n",
            "Epoch 9: val_loss improved from 1.57947 to 1.56933, saving model to model_ruen\n",
            "6334/6334 [==============================] - 924s 146ms/step - loss: 1.5481 - accuracy: 0.2935 - val_loss: 1.5693 - val_accuracy: 0.2956\n",
            "Epoch 10/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5345 - accuracy: 0.2950\n",
            "Epoch 10: val_loss improved from 1.56933 to 1.55959, saving model to model_ruen\n",
            "6334/6334 [==============================] - 925s 146ms/step - loss: 1.5345 - accuracy: 0.2950 - val_loss: 1.5596 - val_accuracy: 0.2977\n",
            "Epoch 11/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5221 - accuracy: 0.2964\n",
            "Epoch 11: val_loss improved from 1.55959 to 1.55342, saving model to model_ruen\n",
            "6334/6334 [==============================] - 924s 146ms/step - loss: 1.5221 - accuracy: 0.2964 - val_loss: 1.5534 - val_accuracy: 0.2974\n",
            "Epoch 12/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5117 - accuracy: 0.2976\n",
            "Epoch 12: val_loss improved from 1.55342 to 1.54673, saving model to model_ruen\n",
            "6334/6334 [==============================] - 925s 146ms/step - loss: 1.5117 - accuracy: 0.2976 - val_loss: 1.5467 - val_accuracy: 0.2995\n",
            "Epoch 13/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.5029 - accuracy: 0.2985\n",
            "Epoch 13: val_loss improved from 1.54673 to 1.54517, saving model to model_ruen\n",
            "6334/6334 [==============================] - 925s 146ms/step - loss: 1.5029 - accuracy: 0.2985 - val_loss: 1.5452 - val_accuracy: 0.2991\n",
            "Epoch 14/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.4946 - accuracy: 0.2995\n",
            "Epoch 14: val_loss improved from 1.54517 to 1.53998, saving model to model_ruen\n",
            "6334/6334 [==============================] - 923s 146ms/step - loss: 1.4946 - accuracy: 0.2995 - val_loss: 1.5400 - val_accuracy: 0.3004\n",
            "Epoch 15/15\n",
            "6334/6334 [==============================] - ETA: 0s - loss: 1.4866 - accuracy: 0.3006\n",
            "Epoch 15: val_loss improved from 1.53998 to 1.53831, saving model to model_ruen\n",
            "6334/6334 [==============================] - 924s 146ms/step - loss: 1.4866 - accuracy: 0.3006 - val_loss: 1.5383 - val_accuracy: 0.3008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b40094f50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "id": "CQ3jGIPB_p_y"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "XoJczN_ECNQd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XoJczN_ECNQd"
    },
    {
      "cell_type": "code",
      "source": [
        "en_sents_test = open('opus.en-ru-test.en').read().lower().splitlines()\n",
        "ru_sents_test = open('opus.en-ru-test.ru').read().lower().splitlines()"
      ],
      "metadata": {
        "id": "u_Ukoi4lCNTJ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "u_Ukoi4lCNTJ"
    },
    {
      "cell_type": "code",
      "source": [
        "text_batches = [en_sents_test[:1000], en_sents_test[1000:]]\n"
      ],
      "metadata": {
        "id": "foKN1Q5qCNVn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "foKN1Q5qCNVn"
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text_batches):\n",
        "\n",
        "  sentences = []\n",
        "\n",
        "  for batch in text_batches:\n",
        "    # Для каждого \"батча\" формируем вектор входных токенов из N предложений\n",
        "    batches = []\n",
        "    for text in batch:\n",
        "      input_ids = encode(text.lower(), tokenizer_en)\n",
        "\n",
        "      batches.append(input_ids)\n",
        "\n",
        "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                                        batches, maxlen=max_len_en, padding='post')\n",
        "\n",
        "\n",
        "    # Формируем вектор выходных токенов с размерностью N\n",
        "    output_ids = [[tokenizer_ru.token_to_id('[CLS]') ]]*input_ids.shape[0]\n",
        "\n",
        "    # Предсказываем батчами\n",
        "    preds = model.predict((input_ids, tf.cast(output_ids, tf.int32)), batch_size=256)\n",
        "\n",
        "    # Получаем предсказания по всем токенам\n",
        "    pred = preds.argmax(2)[:, -1]\n",
        "\n",
        "    # Получаем матрицу из предсказаний до тех пор, пока не достигнем максимальной длины предложения на русском\n",
        "    for i in range(max_len_ru - 1):\n",
        "      # Добавляем в матрицу столбец с предсказаниями\n",
        "      output_ids = np.c_[output_ids, pred]\n",
        "      pred = model.predict((input_ids, tf.cast(output_ids, tf.int32)), batch_size=64).argmax(2)[:, -1]\n",
        "\n",
        "    sentences.extend(output_ids)\n",
        "  \n",
        "  return sentences"
      ],
      "metadata": {
        "id": "BLjUo12zCNYa"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BLjUo12zCNYa"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = translate(text_batches)"
      ],
      "metadata": {
        "id": "nD4pDcZlCNa_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nD4pDcZlCNa_"
    },
    {
      "cell_type": "code",
      "source": [
        "sep_token = tokenizer_ru.token_to_id('[SEP]')\n"
      ],
      "metadata": {
        "id": "kVTqsvqkCUSm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kVTqsvqkCUSm"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [sentence[1:-1 if len(np.where(sentence==sep_token)[0]) == 0 else np.where(sentence==sep_token)[0][0]] for sentence in sentences]\n",
        "sentences = [tokenizer_ru.decode(sentence) for sentence in sentences]\n"
      ],
      "metadata": {
        "id": "THPmFJO2CUVT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "THPmFJO2CUVT"
    },
    {
      "cell_type": "code",
      "source": [
        "bleus = []\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  reference = tokenizer_ru.encode(sentence).tokens\n",
        "  hypothesis = tokenizer_ru.encode(ru_sents_test[i]).tokens\n",
        "\n",
        "bleus.append(nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,  ))"
      ],
      "metadata": {
        "id": "jId5WXbTCUX1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jId5WXbTCUX1"
    },
    {
      "cell_type": "code",
      "source": [
        "(sum(bleus)/len(bleus))*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b4b012-f7d4-4e53-ddc7-f24806895a98",
        "id": "Kq4QiMyiBi-U"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.806687382400554"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "id": "Kq4QiMyiBi-U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обученный на корпусах с семинара трансформер был оценен на всей тестовой выборке по метрике BLEU. В результате качество не очень хорошее, увеличение количества эпох не дает вначимых результатов."
      ],
      "metadata": {
        "id": "MogQNVLcCdTL"
      },
      "id": "MogQNVLcCdTL"
    },
    {
      "cell_type": "markdown",
      "id": "b5aa93d6",
      "metadata": {
        "id": "b5aa93d6"
      },
      "source": [
        "\n",
        "## Задание 2 (2 балла).\n",
        "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/10.pdf \n",
        "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как его применить к паре en-ru на данных из семинара. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обратный перевод** - это способ работы с одноязычными корпусами целевого языка для создания синтетических параллельных корпусов. \n",
        "\n",
        "Исходный язык (source language) -- это язык, с которого переводится текст, целевой язык (target language) -- язык, на который этот текст переводится.\n",
        "\n",
        "При обратном переводе мы обучаем target-to-source трансформер на небольшом параллельном корпусе для перевода одноязычных целевых данных на исходный язык.  Теперь мы можем добавить этот синтетический параллельный корпус (естественные целевые предложения, выровненные с исходными предложениями, переведенными трансформером) к нашим обучающим данным и обучить модель.\n",
        "\n",
        "Например, возьмем пару enru из семинара: мы хотим перевести с русского на английский, но у нас есть только небольшой русско-английский корпус и при этом много одноязычных данных на английском языке. Мы используем небольшой параллельный корпус для построения обратной модели (с английского на русский). Как только мы переведем английский текст на русский, мы сможем добавить этот синтетический параллельный корпус к нашим обучающим данным.\n",
        "\n",
        "В целом обратный перевод работает на удивление хорошо; при обучении на таком полусинтетическом корпусе качество ниже, чем при обучении на таком же количестве естественных данных, всего на 30%."
      ],
      "metadata": {
        "id": "NrSjKfUhTPsC"
      },
      "id": "NrSjKfUhTPsC"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "hw11",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}