{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "homework2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3705663"
      },
      "source": [
        "# Домашнее задание № 2. Мешок слов"
      ],
      "id": "f3705663"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cf72d19"
      },
      "source": [
        "## Задание 1 (3 балла)"
      ],
      "id": "0cf72d19"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a045e99"
      },
      "source": [
        "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
      ],
      "id": "4a045e99"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90b4d453"
      },
      "source": [
        "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберите победителя. \n",
        "\n",
        "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
      ],
      "id": "90b4d453"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "129c4d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068d5691-5c74-40f5-ba38-45c7b20caeb2"
      },
      "source": [
        "!pip install razdel\n",
        "from razdel import tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "id": "129c4d2e",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Scene_ZkvQp6",
        "outputId": "a2105ad3-4f80-4027-e49a-733f4843b2a0"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "id": "Scene_ZkvQp6",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b112bccd-bdf7-4be0-a600-1ef9571c10e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b112bccd-bdf7-4be0-a600-1ef9571c10e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving labeled.csv to labeled (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bbc2365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6092a77-0929-4100-d01b-f86dbc926aef"
      },
      "source": [
        "data = pd.read_csv('labeled.csv')\n",
        "data.toxic.value_counts(normalize=True) #66 процентов твитов нетоксичные"
      ],
      "id": "8bbc2365",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.66514\n",
              "1.0    0.33486\n",
              "Name: toxic, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJEZIheHS1zz"
      },
      "source": [
        "#делим данные на обучающую и тестовую выборки\n",
        "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
        "train.reset_index(inplace=True)\n",
        "test.reset_index(inplace=True)"
      ],
      "id": "lJEZIheHS1zz",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01341538"
      },
      "source": [
        "#векторизация с дефолтной токенизацией\n",
        "default_vectorizer = CountVectorizer()\n",
        "X1 = default_vectorizer.fit_transform(train.comment)\n",
        "X1_test = default_vectorizer.transform(test.comment)\n",
        "y1 = train.toxic.values\n",
        "y1_test = test.toxic.values"
      ],
      "id": "01341538",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1Vfb8Ecqyzd",
        "outputId": "f828f85e-0e54-4b93-e4b2-aa8ec6ff1dae"
      },
      "source": [
        "#обучение классификатора при дефолтной токенизации\n",
        "clf1 = MultinomialNB(alpha=1.)\n",
        "clf1.fit(X1, y1)\n",
        "\n",
        "preds1 = clf1.predict(X1_test)\n",
        "print(classification_report(y1_test, preds1, zero_division=0))"
      ],
      "id": "P1Vfb8Ecqyzd",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.96      0.90       958\n",
            "         1.0       0.89      0.65      0.75       484\n",
            "\n",
            "    accuracy                           0.85      1442\n",
            "   macro avg       0.87      0.80      0.82      1442\n",
            "weighted avg       0.86      0.85      0.85      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3df99cf4"
      },
      "source": [
        "#векторизация с токенизацией razdel_tokenize\n",
        "def natashatokens (data):\n",
        "    tokenized = list(tokenize(data))\n",
        "    tokens = list ()\n",
        "    for t in tokenized:\n",
        "      tokens.append (t.text)\n",
        "    return tokens"
      ],
      "id": "3df99cf4",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwWQpjWcmTLB"
      },
      "source": [
        "natasha_vectorizer = CountVectorizer(tokenizer = natashatokens)\n",
        "X2 = natasha_vectorizer.fit_transform(train.comment)\n",
        "X2_test = natasha_vectorizer.transform(test.comment)\n",
        "y2 = train.toxic.values\n",
        "y2_test = test.toxic.values"
      ],
      "id": "QwWQpjWcmTLB",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vmck2pQw41u",
        "outputId": "23b9b52e-5350-478c-b037-ceff6b7f9ef0"
      },
      "source": [
        "#обучение классификатора при токенизации razdel_tokenize\n",
        "clf2 = MultinomialNB(alpha=1.)\n",
        "clf2.fit(X2, y2)\n",
        "\n",
        "natashapreds = clf2.predict(X2_test)\n",
        "print(classification_report(y2_test, natashapreds, zero_division=0))"
      ],
      "id": "6Vmck2pQw41u",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.96      0.89       958\n",
            "         1.0       0.89      0.61      0.72       484\n",
            "\n",
            "    accuracy                           0.84      1442\n",
            "   macro avg       0.86      0.79      0.81      1442\n",
            "weighted avg       0.85      0.84      0.84      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZY4GTxgY3o9"
      },
      "source": [
        "#если сравнить метрики, то мы увидим, что оба классификатора работают приблизительно одинаково\n",
        "#но в метриках recall и f1-score классификатор с кастомной векторизацией работает стально немного хуже"
      ],
      "id": "KZY4GTxgY3o9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ffa9f76"
      },
      "source": [
        "## Задание 2 (3 балла)"
      ],
      "id": "1ffa9f76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f358949"
      },
      "source": [
        "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
        "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
      ],
      "id": "5f358949"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6qu3cz-qgnjT",
        "outputId": "97d805ea-6b29-45c0-8d43-109bfbb9ffba"
      },
      "source": [
        "#таблица с абсолютными частотностями\n",
        "df = pd.DataFrame({\"я\" : [1, 1, 3, 1, 0],\n",
        "                 \"ты\" : [1, 1, 0, 0, 0],\n",
        "                 \"и\" : [1, 1, 1, 0, 0],\n",
        "                 \"только\" : [0, 0, 1, 1, 0],\n",
        "                 \"не\" : [0, 0, 0, 1, 0],\n",
        "                 \"он\" : [0, 0, 0, 0, 1]})\n",
        "df = df.rename({0: \"я и ты\", 1: \"ты и я\", 2: \"я, я и только я\", 3: \"только не я\", 4: \"он\"})\n",
        "df"
      ],
      "id": "6qu3cz-qgnjT",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>я</th>\n",
              "      <th>ты</th>\n",
              "      <th>и</th>\n",
              "      <th>только</th>\n",
              "      <th>не</th>\n",
              "      <th>он</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>я и ты</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ты и я</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>я, я и только я</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>только не я</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>он</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 я  ты  и  только  не  он\n",
              "я и ты           1   1  1       0   0   0\n",
              "ты и я           1   1  1       0   0   0\n",
              "я, я и только я  3   0  1       1   0   0\n",
              "только не я      1   0  0       1   1   0\n",
              "он               0   0  0       0   0   1"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1FMxN36icMm",
        "outputId": "eff52af3-3da3-415d-99bf-1b2875732c54"
      },
      "source": [
        "#total number of docs N\n",
        "df.index.size"
      ],
      "id": "c1FMxN36icMm",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6QLIlCNDytk",
        "outputId": "a94224c9-4dee-4098-b6d2-3cae5206de4a"
      },
      "source": [
        "#таблица с tfidf значениями\n",
        "values = []\n",
        "for i in df.index:\n",
        "  #print (i)\n",
        "  tfidf_list = []\n",
        "  for column in df.columns:\n",
        "    #print (column)\n",
        "    x = df[column].loc[i]\n",
        "    words_count = 0\n",
        "    for j in df.loc [i]:\n",
        "      words_count += j\n",
        "    tf = x / words_count\n",
        "    tfidf = tf * math.log (df.index.size / np.count_nonzero(df[column]))\n",
        "    tfidf_list.append (tfidf)\n",
        "  values.append (tfidf_list)\n",
        "values"
      ],
      "id": "i6QLIlCNDytk",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.07438118377140325, 0.3054302439580517, 0.1702752079219969, 0.0, 0.0, 0.0],\n",
              " [0.07438118377140325, 0.3054302439580517, 0.1702752079219969, 0.0, 0.0, 0.0],\n",
              " [0.13388613078852585,\n",
              "  0.0,\n",
              "  0.10216512475319815,\n",
              "  0.18325814637483104,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.07438118377140325, 0.0, 0.0, 0.3054302439580517, 0.5364793041447, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 1.6094379124341003]]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sg3uT1AFJalK",
        "outputId": "1a811fc5-340b-4277-9f07-0a2094771a0b"
      },
      "source": [
        "pd = pd.DataFrame(values, index = df.index, columns = df.columns)\n",
        "pd"
      ],
      "id": "sg3uT1AFJalK",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>я</th>\n",
              "      <th>ты</th>\n",
              "      <th>и</th>\n",
              "      <th>только</th>\n",
              "      <th>не</th>\n",
              "      <th>он</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>я и ты</th>\n",
              "      <td>0.074381</td>\n",
              "      <td>0.30543</td>\n",
              "      <td>0.170275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ты и я</th>\n",
              "      <td>0.074381</td>\n",
              "      <td>0.30543</td>\n",
              "      <td>0.170275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>я, я и только я</th>\n",
              "      <td>0.133886</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.102165</td>\n",
              "      <td>0.183258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>только не я</th>\n",
              "      <td>0.074381</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.305430</td>\n",
              "      <td>0.536479</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>он</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.609438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        я       ты         и    только        не        он\n",
              "я и ты           0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
              "ты и я           0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
              "я, я и только я  0.133886  0.00000  0.102165  0.183258  0.000000  0.000000\n",
              "только не я      0.074381  0.00000  0.000000  0.305430  0.536479  0.000000\n",
              "он               0.000000  0.00000  0.000000  0.000000  0.000000  1.609438"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f5bc8de"
      },
      "source": [
        "## Задание 3 (2 балла)"
      ],
      "id": "2f5bc8de"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8961bbf"
      },
      "source": [
        "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
      ],
      "id": "f8961bbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46681ef"
      },
      "source": [
        "Требования к классификаторам:   \n",
        "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
        "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
        "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
        "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
      ],
      "id": "b46681ef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed77d7b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c97ba6-de10-4efb-be10-e6eab0c2a11e"
      },
      "source": [
        "#Naive Bayes + CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(lowercase=True, tokenizer = natashatokens, max_df=0.5, min_df=10, max_features=3000)\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values\n",
        "\n",
        "clf = MultinomialNB(alpha=1., fit_prior=True)\n",
        "clf.fit(X, y)\n",
        "nb_preds = clf.predict(X_test)\n",
        "nb_probas = clf.predict_proba(X_test)\n",
        "\n",
        "print(classification_report(y_test, nb_preds))"
      ],
      "id": "ed77d7b1",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.90      0.88       967\n",
            "         1.0       0.78      0.69      0.73       475\n",
            "\n",
            "    accuracy                           0.83      1442\n",
            "   macro avg       0.82      0.80      0.81      1442\n",
            "weighted avg       0.83      0.83      0.83      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irlUUXI-x7Bw"
      },
      "source": [
        "#функция для нахождения 10 токсичных комментов\n",
        "def find_toxic(probas):\n",
        "  probas = [p[1] for p in probas]\n",
        "  test['probas'] = probas\n",
        "\n",
        "  res = test.sort_values(by = 'probas', ascending = False)[:10]\n",
        "  res = res.reset_index(drop=True)\n",
        "\n",
        "  for i in range(10):\n",
        "    print('toxic:', res.loc[i].toxic)\n",
        "    print('comment: ', res.loc[i].comment)\n",
        "  return (res)"
      ],
      "id": "irlUUXI-x7Bw",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEz3klk9t-p1",
        "outputId": "4afd71c9-347f-49c9-d4d8-2073fb738d32"
      },
      "source": [
        "#топ-10 токсичных комментариев для классификатора Naive Bayes + CountVectorizer\n",
        "print (find_toxic(nb_probas))"
      ],
      "id": "UEz3klk9t-p1",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic: 0.0\n",
            "comment:  Конечно, это резонансное событие требует отдельного треда для обсуждения и 19 тредов до этого шло обсуждение. Тред назывался нейтрально Рассстрел мусульман в новозеландской мечети . Но сегодня ОП, по совместительству борец за Арийскую Раssy и мамкин фашик назвал его в честь стрелка KEBAB REMOVER(англ. уничтожитель чурок ) и с утра пораньше решил в ОП-посте(заголовке треда) обозначить тред, как героизирующий(в первом треде) и оправдывающий(в третьем треде) терракт этого стрелка. Пик стронгли релейтед. 20 тред. В третьей строке заголовка ОП восхваляет и героизирует террориста, цитирую заголовок: KEBAB REMOVER тред 20 Продолжаем пиздеть тут. Слава Герою! Я репортил тред в форме репорта и в прикрепе в d , реакции никакой. Видимо, школомодеры сами симпатизируют нацизму и закрывают на это глаза. 21 тред. После того, как я пригрозил ему репортом, в этот раз мамкин фашик, убирает строку про героя и зачем-то вместо неё ставит нацистское приветствие дивизии СС Галичина. KEBAB REMOVER тред 21 Продолжаем пиздеть тут. Слава Украiнi! 22 тред. В этот раз тот же остроумный ОП поставил на третью строчку PRESS R TO PAY RESPECT!(англ. Нажмите R, чтобы выразить уважение!) т.е. уважение стрелку за то, что он совершил терракт. Еще он выделил жирным шрифтом предложение Именно эту мечеть он выбрал потому, что на её месте раньше находилась церковь. , будто то бы для оправдания стрелка. KEBAB REMOVER тред 22 Продолжаем пиздеть тут. PRESS R TO PAY RESPECT! Эти действия подпадают под конкретные статьи УК РФ, (публичное оправдание терроризма или пропаганда терроризма), а модерация никак не трёт такие заголовки треда, не реагирует на репорты. Да, я понимаю, что на Дваче возможна любая точка зрения, но хотя бы шапка треда должна быть нейтральной и уж точно не должна оправдывать и героизировать терроризм фашизм и не нарушать законодательство. Такое название треда автоматически собирает в нём нацистскую падаль и сворачивает обсуждение в сторону фашистской идеологии.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  ты, блять, троллишь чтоли или просто перепутал двачи и ебаный тупичок? Да. Зашёл вот, блять, ответами на тыщу слов потраллировать. Дебс блять, если бы траллировал я бы просто постил анимешные смаг фейсы. Всегда работает. ебаные оправдания для любого коммуняки, особенно такого тупого, как ты, стас и вестник дури. Оправдания ЧЕГО? Оправдываться надо за проступок. Идеологий коммунизма не подразумевает что ты должен пиздовать и раздавать все деньги полученные капиталистическим путём в капиталистической системе людям живущим в капиталистической систем и которые потратят их на капиталистические нужды. Начём вообще с того что КОММУНИЗМ ПОДРАЗУМЕВАЕТ ОТКАЗ ОТ ДЕНЕГ КАК ТАКОВЫХ. Ты считаешь коммунистов какими-то манямирковыми ебланами из-за анальных форсов со всех сторон. Но нет, друг мой, коммунисты это материалисты и логики, коммунисты это реалисты. Всем прекрасно понятно что в современном мире без денег не выжить и что помощь единицам не изменит ничего. Коммунизм основан на рациональности и подразумевает то, что он выгоден самим коммунистам. Отказ от всего в капиталистическом мире - нихуя не выгодно. Выгоднее использовать эти ресурсы для распространения коммунизма. Так вот. Нигде, блять, не сказано что коммунист должен жить в говне, жрать говяжий анус и раздавать все деньги. Коммунист должен распространять идеи коммунизма чтобы люди становились коммунистами. В этом суть. И Стас это делает. так чего же не вернулся обратно, чтобы быть более значимым? ах да, 700к в месяц с его же слов с хлебобулочного и продажи мобилок не падают, а зарплаты жене и корешу платить же надо Ну да. Ему нравилось работать на хлебобулочном, но там зарплата 20к. А тут он делает ролики и получает 700к. Еще раз, дружок, коммунизм это не про ИДЕАЛИСТИЧЕСКИЙ ОТКАЗ ОТ ВСЕГО НА СВЕТЕ. Коммунизм это про материалистическую и логическую справедливость. Идеи коммунизма и Стаса заключатся в том, чтобы тот кто делает ролики получал 100к и тот кто работает на заводе получал 100к. Тогда вот он вернётся на завод. Условно. Естественно он против того чтобы кто-то вообще делал ролики на ютубе и жил за счёт этого. Еще раз. Суть коммунизма не в том, чтобы жрать говяжьи анусы за идею, а в том чтобы мир был справедлив, и тебе не надо было бы жрать их потому что угнетатель решил закупить себе танкер чёрной игры. при слове раскулачиться стас подставляет жопу, он думает, что это значит немного другое Стас представляет что он, отдаст свою студию, свой канал и пойдёт работать на завод за достойные деньги. Как и вся страна. А что ты имел в виду? а первое государство с коммунистическим строем уебало кучу народа Опять начинаешь охуительные истории про миллиард младенцев изнасилованных и убитых лично Сталиным? Сколько человек было убито коммунистами? 300к белой гвардии, 50-70к восставших крестьян. Всё. Белая гвардия вообще не люди, а крестьян да, жалко, надо было им добровольно раскулачиваться. Все эти охуительные сказки про гулаги и голодоморы уже были разъёбаны 1000 раз на ютубе. Чекай каналы Сёмина, Тубуса и Вестника Бури. компьютеры могут служить не только для того, чтобы играть в доту2, но и для того, чтобы построить коммунизм - ору до сих пор. Что смешного? Дефолтный политспич человека, который чувствовал себя неуютно из-за врождённой стеснительности. отвечу цитатой стаса: А ЕЖИ? . Так же ответочка на доёбы ежи до стакана и прочей хуйни. к вилсе Нет. поперечному Нет. соболеву Нет. маргиналу Нет. вечному Кому ёпта? ежи Доёбывался. Потому что это был такой же уровень аргументации как доёб до стакана. Ответ тем же оружием.\n",
            "\n",
            "toxic: 0.0\n",
            "comment:  Все согласны, блядь. Всем по полному ебучему завтраку, подводит итог Бегби. Рентон не верит своим ушам. Ему хочется послать Бегби на хуй. Но он перебарывает этот порыв и только медленно качает головой: Я не ем мяса, Франко. баное вегетарианство. баный пиздёж. Ты должен есть мясо. баный торчок заботится, на хуй, о том, что он вводит в свой в организм! Я угораю, бля! Просто я не люблю мяса, отвечает Рентон, чувствуя себя полным дураком, и все начинают хихикать. Только не пизди мне о том, что тебе жалко ёбаных животных. Вспомни тех ёбаных собак и кошек, в которых мы с тобой, на хуй, стреляли из духовых ружбаек! А ещё ёбаных голубей, которых мы жгли живьём. Этот чувак делал ебучие шутихи типа как фейерверки из белых мышей. Мне не жалко животных. Просто я не могу их есть, Рентон пожимает плечами, смущённый тем, что Келли узнала о его подростковых зверствах. Бессердечные ублюдки. Не представляю, как можно выстрелить в собаку, ехидничает Элисон, качая головой. А я не представляю себе, как можно убить и съесть свинью, Рентон показывает на бекон и сосиску у неё на тарелке. Это разные вещи. Картошка озирается вокруг: Это, э, это самое Рентс поступает правильно, но только типа как неправильно объясняет. Мы никогда, это самое, не научимся любить друг друга, если не будем заботиться о тех, кто слабее нас, это самое, животных там, и всё такое но хорошо, что Рентс вегетарианец это самое, если ты можешь воздерживаться это самое Бегби неуклюже трясётся всем телом и жестом заставляет Картошку замолчать. Остальные смеются. Рентон, благодарный Картошке за попытку поддержать его, вмешивается, чтобы перевести огонь на себя. Дело не в воздержании. Просто я терпеть не могу мяса. Меня от него тошнит. Вот и всё. И всё равно я говорю, блядь, что ты хочешь всё, на хуй, пересрать. Почему? Потому что я так сказал, блядь, вот почему, на хуй! шипит Бегби, показывая на себя. Рентон опять пожимает плечами. Спорить дальше нет смысла. Самые эгоистичные люди - это вегетарианцы, да.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Ну давай разберём всё тобой написанное. Бляядь, вы действительно думаете вы лучше пидорашек? Ну в целом, всё что живёт в рашке - затронуто говномидасом, но никто тут это не признает. сейчас воспитывают массу хороших кодеров В соседнем треде обоссали уже. Иди обтекай. Вы унижаете русских детей в школе Я учился в рашке и у нас был класс, который состоял онли из русачков. Думаешь, что то изменилось? Чурки тебе говна в жопу залили и заставили русачков в классе кошмарить омежных русачков? Я не люблю выражаться фразами нациков, но вы воистину столетия просто сидели в горах и ебали баранов, вас даже народ-пидор смог захватить. Плоховато ты знаешь историю. Когда русня пришла на Кавказ, тут всё уже было поделено османами и персами. А потом РИ наебала персов и постоянно нападала на османов высасывая причины из пальца, в принципе, русачки, что от них ещё было ожидать. В прошлом вы (чеченцы, даги и прочие сорта) были просто дикарями...А если говорить о среднеазиатах, которые бугуртят с оккупации, то вы были обычными нищими кочевниками Очередной акт незнания истории. Например у кавказцев по факту у народов отвественных за этногенез дагов и азеров уже был Дербент, а русачков даже в планах не было. Почитай историю Кавказа и Средней Азии, там были и локальные империи и нагибы округи и прочее и прочее. Называют русских пидорашками, славщитом. Говоришь это так, будто бы в этом что то плохое. У меня знакомые po рашеры irl, которые являются русскими и которые ссут на русню с ещё большей колокольни чем я Сейчас вас все боятся потому, что если пидорашка сделает в вас пару дырок, защищая себя, то его посадят на бутылку, а если вы убьёте пидорашку, то вам нихуя не будет. Может потому что в рашке мочить с волыны ножа человека, который идёт на тебя с кулаками - превышение пределов самообороны? Кто виноват в том, что русня настолько вырожденческая, что один чеченский доходяга ставит на колени группу русачков? Ты думаешь, будь руснявая гопота менее вырожденческая, то так же людей не кошмарила? Кто виноват, что вы морозитесь или даёте по съебатору, когда видите, как вашего славянского друга избивают унижают? Да чего уж там, тот митинг вспомните, где жирик, какого то парня на колени поставил и все вокруг стоят и снимают, словно стадо руснявых баранов. Зуб даю, в той толпе стояли его друзья и знакомые. Лично для меня это пиздец, особенно проигрываю, когда там не какой нибудь братуха-борцуха, а смарчёк чеченский. Никогда бы не бросил и не бросал друга в таком пиздеце и не важно, какой нации был друг, а какой нападавший. Вся ваша проблема не том, что вы слабками, не в том, что большинство русачков еблом похож на свинью, не в том, что за тысячу лет существования не смогли построить нормальную цивилизацию и другим не давали. Проблема в обыкновенной ошибке выжившего, вы видите кавказское быдло гопника, потому что оно в среднем сильнее, напористее, агрессивнее и образ кавказца, как лица которое представляет опасность выжигается у вас в мозгах, при этом не хотите замечать, что у вас, целые города набитые руснявыми АУЕшниками, потому что один среднестатистический руснявый гопник ауешник быдлойд сосёт у одного среднестатистического чуркобесского гопника быдлойда. В конечном итоге русачков в станице кущевской ебал кто? Другие русачки. В школу приезжали и выберали лолей на поёбку кто? Другие русачки. Сжигал русачков кто? Другие русачки. Всё вскрылось совершенно случайно. Сколько таких станиц, деревень и городов по всей рашке? аз-кун\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  хорошо тут все ясно а теперь поясни мне за то что он кладет на репорты за шитпостинг и нерелейтед. айробусом дедом, лизон создали тред, карине создали тред, оляше создали тред, так какого хуя этим ебланам треды отдельные не создать? какого хуя ты тут чертила свой рот открываешь, тварь малолетняя, вот из за таких как ты уебанов все и скатилось в гавно, потому что черта этого никто не репортит, а такие говноеды как ты все сливают в парашу\n",
            "\n",
            "toxic: 0.0\n",
            "comment:  Возьмём как пример Россию, западноевропейские страны и США. Идёт метисация, сознательная политика замещения белого населения на пришлое черно-коричневое. Идёт создание новой расы метисов, исламизация и почернение. В крупных городах половина населения - выходцы из ебеней Мексики, Африки, Ближнего Востока, а в случае с Россией - Кавказа и Средней Азии. Этнические ниггеро-арабские гетто верят на хую законы как хотят, чудовищная по масштабам этническая преступность. Говорить о миграции и тем более затрагивать тему замещения коренного населения властями нельзя, иначе бутылка. Свобода слова тут не для вас, молодой человек. При этом говорить о том, что белые должны вымереть, и это нормально - можно. Белые официально вымирают ведётся пропаганда так или иначе направленная на снижение рождаемости белого населения. Феминизм, ЛГБТ, чайлдфри. Каждая женщина в Швеции - леволиберальная феминистка, это страна победившего феминизма. Что сегодня там происходит - страшно делается. Пропагандируются смешанные браки, межрасовые браки, пропагандируется превосходство детей-метисов. Идёт демонизация белых и пропаганда превосходства чёрных и смуглых мужчин, форс отношений белая женщина смуглый чёрный мужчина-мигрант. Как результат - всё больше чернильниц, всё больше смешанных браков, всё больше небелых метисов. Белые женщины просто не хотят контактировать с мужчинами своей нации и расы, наделяя их самыми плохими качествами и обожествляя черных. При этом большинство белых не считает завоз чурок чем-то плохим, наоборот, относятся к ним толерантно. Проводится политика насаждения толерантности, мультикультурализма, политкорректности и космополитизма. Набирающее популярность даже в России SJW - это вообще отдельная тема для обсуждения. Всё вышеперечисленное относится к сильнейшим когда-то странам, бывшим империям, нагибающим слабых. Сегодня происходит так, что бывшие империи в прямом смысле деградируют, вырождаются и вымирают, а место сильнейших когда-то, господствующих народов, занимают те, кого когда-то колонизировали. Во Франции к 2080 уже будут доминировать негры и арабы, в России - кавказцы и выходцы из средней Азии, в Великобритании - индийцы, негры, арабы, пакистанцы, etc. А в маленьких, нейтральных странах, вроде Словении или Беларуси, Литвы или Чехии, Румынии или Эстонии - всё пучком. Им вымирание не грозит, они остаются и будут оставаться белыми. Более того, у них ведётся политика, направленная на сохранение традиционных ценностей и культуры коренного населения. Они сказали беженцам нет . В Польшу, например, русскому или украинцу гораздо легче переехать и остаться, чем арабу или африканцу. В Германии ситуация противоположная, белых там не ждут. Польша, Чехия, Словакия, Венгрия, Словения, Хорватия, Сербия, БиГ, Черногория, Македония, Греция, Болгария, Румыния, Молдова, Украина, Беларусь, Литва, Латвия, Эстония - вот Европа будущего. Скандинавия, Южная, Западная Европа, а также Россия - лишатся коренного населения и своей культуры.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  В России два пола. Гомосеком быть стыдно и опасно. Негры - это негры, а не афроктототам. Женщины имеют больше прав, чем мужчины. Вот поэтому и ебутся со всеми делами, раз такие умные. Аборты - а тебе не похуй? Или денег захотел дать? Ну, давай. Остоебенело читать подзалупную иностранщину. Для кого это говно переводят на наш язык? Нам до этой благородной подагры ещё коклюшами со скарлатинами два века с гаком болеть. Горчичники надо учиться крутить, а не за мусьё тарелки подлизывать.\n",
            "toxic: 1.0\n",
            "comment:  А мышление тебе дебилу формирует телевизор Неверно. значит, бла-бла-бла Не значит. Мне его формирует не телевизор, а люди, знакомые и незнакомые. То есть общество. Это нормально. Я, в свою очередь, общаясь с ними, тоже отчасти формирую их мышление. А печень чистит кровь для тебя, значит ты высшая форма печени. Весь мой организм, включая печень, работает на меня, и да, действительно, я есть высшая форма многоклеточной жизни. Я - это нервные импульсы, которые крутятся на нейронном хардвэре, который сидит в костяной коробке в голове. А с чего ты, дебил, взял, что тут идет от низкого к высокому? Мне так удобно, этого вполне достаточно. Можно поставить пирамиду на основание, можно как-то закрепить вершиной вниз - пирамидой она быть не перестанет. А можно организовать физику без химии? Ты ж тут лихо применил какие-то названия к явлениям окружающего мира. И поставил их в логическую цепочку. Что ты подразумеваешь под словосочетанием организовать физику , наркоман? Русский язык неродной штоле? Применять названия к явлениям - это абсолютно нормально для людей. Мы думаем на языке, без названий и определений ты не можешь мыслить. Точно так же нормально строить логические цепочки, не понимаю, в чём претензии. А если ты ебнешь палкой и произойдет физическое взаимодействие это значит оно по кругу пошло? Разумеется. Чтобы ёбнуть палкой, надо сперва возбудить нервую систему определенным образом, потратить химическую энергию АТФ в мышцах и перевести её в кинетическую, потом она при столкновении палки с целью перейдёт в тепловую энергию движения молекул, а потом в лучистую в виде инфракрасного излучения. Дебил тут только ты.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Свобода слова,говоришь? Я ИМЕЛ ТВОЮ МАМАШУ ВО ВСЕ ЩЕЛИ! Это тоже свобода слова. И когда на улице кавказец при твоих друзьях или знакомых назовет тебя пидарасом,это тоже свобода слова. Свобода слова это палка о двух концах. Любая палка имеет другой конец,которым ты можешь получить по ебалу. Но ты очевидно школьник или студент-младшекурсник,или просто великовозрастный дебил,поэтому это для тебя неочевидно.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Какой же ты тупой блять и того маргинал поменял свою позицию 1 раз,потому что остальные пункты друг другу не противоречат,какой же ты тупой мудак,просто ахуеть. И про аборты также Ты долбоёб, он с 15ого года ни разу не поменял свою позицию по абортам и всегда говорил почему, смотрит он конфу со времёен Витюни. Смех да и только.\n",
            "\n",
            "   index                                            comment  toxic  probas\n",
            "0    172  Конечно, это резонансное событие требует отдел...    0.0     1.0\n",
            "1   6410  ты, блять, троллишь чтоли или просто перепутал...    1.0     1.0\n",
            "2    829  Все согласны, блядь. Всем по полному ебучему з...    0.0     1.0\n",
            "3     41  Ну давай разберём всё тобой написанное. Бляядь...    1.0     1.0\n",
            "4    241  хорошо тут все ясно а теперь поясни мне за то ...    1.0     1.0\n",
            "5     35  Возьмём как пример Россию, западноевропейские ...    0.0     1.0\n",
            "6   1520  В России два пола. Гомосеком быть стыдно и опа...    1.0     1.0\n",
            "7   6483  А мышление тебе дебилу формирует телевизор Нев...    1.0     1.0\n",
            "8    176  Свобода слова,говоришь? Я ИМЕЛ ТВОЮ МАМАШУ ВО ...    1.0     1.0\n",
            "9  13859  Какой же ты тупой блять и того маргинал поменя...    1.0     1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cd916f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72c299b-ca64-473f-e8ea-95c45039afb8"
      },
      "source": [
        "#LogisticRegression + TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(lowercase=True, tokenizer = natashatokens, max_df=0.5, min_df=10, max_features=3000)\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values\n",
        "\n",
        "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
        "clf.fit(X, y)\n",
        "lr_preds = clf.predict(X_test)\n",
        "lr_probas = clf.predict_proba(X_test)\n",
        "\n",
        "print(classification_report(y_test, lr_preds))"
      ],
      "id": "7cd916f1",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.86      0.87       967\n",
            "         1.0       0.73      0.76      0.74       475\n",
            "\n",
            "    accuracy                           0.83      1442\n",
            "   macro avg       0.80      0.81      0.81      1442\n",
            "weighted avg       0.83      0.83      0.83      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKLmYUyN1p2s",
        "outputId": "da2ae208-ba96-4c3e-94bf-5c1a5bc0049c"
      },
      "source": [
        "#топ-10 токсичных комментариев для классификатора LogisticRegression + TfidfVectorizer\n",
        "print (find_toxic(lr_probas))"
      ],
      "id": "MKLmYUyN1p2s",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic: 0.0\n",
            "comment:  Ты крутая. Бэнкси отдыхает\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  ебать ты конченый, нахуя ты это постишь?\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Валентин ты опять таблетки не выпил\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Да мы поняли что ты пидорьё ебаное, поляк наверное. Иди уроки выучи, портфель собери, че ты.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Что. ты. несёшь. дегенерат?\n",
            "toxic: 1.0\n",
            "comment:  Вольнова же повесили на параше, ты про что?\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  Я тебе дохуя пруфов привёл, а ты ебанный дебил не верил. Сося должен был вам сказать, но сося долбаёб и тебя за человека не держит, почему он тебе должен рассказывать о своих фейл, если его заявляения раньше звучали гордо . Ебать ты дибил.\n",
            "\n",
            "toxic: 0.0\n",
            "comment:  А ты вспомни чем Женя Лукашин салатницу мыл\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  А почему ты упустил вот это Ты не упустил. Молодец.\n",
            "\n",
            "toxic: 1.0\n",
            "comment:  да пошел ты нахуй сашенька ебаный\n",
            "\n",
            "   index                                            comment  toxic    probas\n",
            "0    837                       Ты крутая. Бэнкси отдыхает\\n    0.0  0.981370\n",
            "1    795         ебать ты конченый, нахуя ты это постишь?\\n    1.0  0.944031\n",
            "2  13706              Валентин ты опять таблетки не выпил\\n    1.0  0.917055\n",
            "3     81  Да мы поняли что ты пидорьё ебаное, поляк наве...    1.0  0.910583\n",
            "4   1963                        Что. ты. несёшь. дегенерат?    1.0  0.902219\n",
            "5   2020      Вольнова же повесили на параше, ты про что?\\n    1.0  0.896613\n",
            "6   5685  Я тебе дохуя пруфов привёл, а ты ебанный дебил...    1.0  0.896363\n",
            "7    788      А ты вспомни чем Женя Лукашин салатницу мыл\\n    0.0  0.894184\n",
            "8   5473  А почему ты упустил вот это Ты не упустил. Мол...    1.0  0.893920\n",
            "9    531                да пошел ты нахуй сашенька ебаный\\n    1.0  0.893679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUuHgQC6BBTq"
      },
      "source": [
        "#в итоге ни один текст не совпал и не все тексты токсичные:\n",
        "#в выборку классификатора Naive Bayes с CountVectorizer попали 3 нетоксичных комментария, LogisticRegression + TfidfVectorizer сработал чуть точнее\n",
        "#практически во всех твитах есть маты и жаргон, что влияет на высокий уровень токсичности"
      ],
      "id": "YUuHgQC6BBTq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68324753"
      },
      "source": [
        "## *Задание 4 (2 балла)"
      ],
      "id": "68324753"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7794f97"
      },
      "source": [
        "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
        "\n",
        "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
      ],
      "id": "c7794f97"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcV6p6ZTPvnL",
        "outputId": "63a6dfdc-9716-49be-ac6a-4c8d7799d2bc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
        "train = train.reset_index(drop=True) \n",
        "test = test.reset_index(drop=True) \n",
        "\n",
        "vectorizer = CountVectorizer(stop_words = russian_stopwords, min_df = 10, max_df = 0.5)\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ],
      "id": "kcV6p6ZTPvnL",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTQR-cIbGiuk",
        "outputId": "68ac21e7-4d06-4b2b-a840-2b5843b22b45"
      },
      "source": [
        "#Logistic Regression\n",
        "clf = LogisticRegression(C = 0.2, solver = 'liblinear', class_weight = 'balanced')\n",
        "clf.fit(X,y)\n",
        "\n",
        "importance = clf.coef_\n",
        "\n",
        "toxic = {}\n",
        "for key, value in vectorizer.vocabulary_.items():\n",
        "  toxic[value] = key\n",
        "\n",
        "top = importance.argsort()\n",
        "for i in top[0][:-6:-1]:\n",
        "    print(toxic[i])"
      ],
      "id": "XTQR-cIbGiuk",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хохлы\n",
            "хохлов\n",
            "дебил\n",
            "тебе\n",
            "тупые\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo6lp0mRMk4t",
        "outputId": "4ce9478a-dc40-4a61-c035-03c0166692cb"
      },
      "source": [
        "#Naive Bayes\n",
        "clf = MultinomialNB(alpha=1.)\n",
        "clf.fit(X,y)\n",
        "\n",
        "importance = clf.coef_\n",
        "\n",
        "toxic = {}\n",
        "for key, value in vectorizer.vocabulary_.items():\n",
        "  toxic[value] = key\n",
        "\n",
        "top = importance.argsort()\n",
        "for i in top[0][:-6:-1]:\n",
        "    print(toxic[i])"
      ],
      "id": "Zo6lp0mRMk4t",
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "это\n",
            "просто\n",
            "тебе\n",
            "почему\n",
            "всё\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "nDZmSt-WCVhX",
        "outputId": "e0542a38-26bf-43e7-8177-dc3196aa01b9"
      },
      "source": [
        "#для начинающих очень тяжелое задание\n",
        "from IPython.display import Image\n",
        "Image(url=\"https://i.pinimg.com/originals/6b/84/c6/6b84c674c24beae23ca5df2ffee1fd96.jpg\",\n",
        "     width=380, height=500)"
      ],
      "id": "nDZmSt-WCVhX",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/originals/6b/84/c6/6b84c674c24beae23ca5df2ffee1fd96.jpg\" width=\"380\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    }
  ]
}